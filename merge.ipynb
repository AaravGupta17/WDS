{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "df = pd.DataFrame(pd.read_excel('./datasci/cleanedup/whl_2025_base.xlsx'))\n",
    "df.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "IDENTIFIERS:\n",
    "- game_id\n",
    "- record_id\n",
    "\n",
    "ENTITIES:\n",
    "- home_team\n",
    "- away_team\n",
    "- home_goalie\n",
    "- away_goalie\n",
    "\n",
    "CONTEXT:\n",
    "- home_off_line\n",
    "- away_off_line\n",
    "- home_def_pairing\n",
    "- away_def_pairing\n",
    "- went_ot\n",
    "\n",
    "OUTCOMES:\n",
    "- home_goals\n",
    "- away_goals\n",
    "- home_shots\n",
    "- away_shots\n",
    "- home_penalties_committed\n",
    "- away_penalties_committed\n",
    "\n",
    "DERIVED METRICS:\n",
    "- home_xg\n",
    "- away_xg\n",
    "- home_max_xg\n",
    "- away_max_xg\n",
    "'''"
   ],
   "id": "faab0f458fe5456f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sum_cols = [\n",
    "    \"home_goals\", \"away_goals\",\n",
    "    \"home_shots\", \"away_shots\",\n",
    "    \"home_xg\", \"away_xg\",\n",
    "    \"home_assists\", \"away_assists\",\n",
    "    \"home_penalties_committed\", \"away_penalties_committed\",\n",
    "    \"home_penalty_minutes\", \"away_penalty_minutes\"\n",
    "]\n",
    "first_cols = [\n",
    "    \"home_team\",\n",
    "    \"away_team\",\n",
    "    \"went_ot\"\n",
    "]\n",
    "agg_dict = {}\n",
    "\n",
    "for col in sum_cols:\n",
    "    agg_dict[col] = \"sum\"\n",
    "\n",
    "for col in first_cols:\n",
    "    agg_dict[col] = \"first\"\n",
    "games = (\n",
    "    df\n",
    "    .groupby(\"game_id\", as_index=False)\n",
    "    .agg(agg_dict)\n",
    ")\n",
    "games.shape\n",
    "games[\"home_score\"] = games[\"home_goals\"]\n",
    "games[\"away_score\"] = games[\"away_goals\"]\n",
    "\n",
    "games[\"goal_diff\"] = games[\"home_score\"] - games[\"away_score\"]\n",
    "games[\"total_goals\"] = games[\"home_score\"] + games[\"away_score\"]\n",
    "\n",
    "games[\"shot_diff\"] = games[\"home_shots\"] - games[\"away_shots\"]\n",
    "games[\"total_shots\"] = games[\"home_shots\"] + games[\"away_shots\"]\n",
    "\n",
    "games\n",
    "\n",
    "home_games = games.copy()\n",
    "\n",
    "home_games[\"team\"] = home_games[\"home_team\"]\n",
    "home_games[\"opponent\"] = home_games[\"away_team\"]\n",
    "\n",
    "home_games[\"goals_for\"] = home_games[\"home_score\"]\n",
    "home_games[\"goals_against\"] = home_games[\"away_score\"]\n",
    "\n",
    "home_games[\"shots_for\"] = home_games[\"home_shots\"]\n",
    "home_games[\"shots_against\"] = home_games[\"away_shots\"]\n",
    "\n",
    "home_games[\"xg_for\"] = home_games[\"home_xg\"]\n",
    "home_games[\"xg_against\"] = home_games[\"away_xg\"]\n",
    "\n",
    "home_games[\"is_home\"] = 1\n",
    "away_games = games.copy()\n",
    "\n",
    "away_games[\"team\"] = away_games[\"away_team\"]\n",
    "away_games[\"opponent\"] = away_games[\"home_team\"]\n",
    "\n",
    "away_games[\"goals_for\"] = away_games[\"away_score\"]\n",
    "away_games[\"goals_against\"] = away_games[\"home_score\"]\n",
    "\n",
    "away_games[\"shots_for\"] = away_games[\"away_shots\"]\n",
    "away_games[\"shots_against\"] = away_games[\"home_shots\"]\n",
    "\n",
    "away_games[\"xg_for\"] = away_games[\"away_xg\"]\n",
    "away_games[\"xg_against\"] = away_games[\"home_xg\"]\n",
    "\n",
    "away_games[\"is_home\"] = 0\n",
    "team_games = pd.concat([home_games, away_games], ignore_index=True)\n",
    "team_games[\"goal_diff\"] = team_games[\"goals_for\"] - team_games[\"goals_against\"]\n",
    "\n",
    "team_games[\"win\"] = (team_games[\"goal_diff\"] > 0).astype(int)\n",
    "team_games[\"loss\"] = (team_games[\"goal_diff\"] < 0).astype(int)\n",
    "team_season = (\n",
    "    team_games\n",
    "    .groupby(\"team\", as_index=False)\n",
    "    .agg(\n",
    "        games_played=(\"team\", \"count\"),\n",
    "        wins=(\"win\", \"sum\"),\n",
    "        losses=(\"loss\", \"sum\"),\n",
    "        goals_for=(\"goals_for\", \"sum\"),\n",
    "        goals_against=(\"goals_against\", \"sum\"),\n",
    "        shots_for=(\"shots_for\", \"sum\"),\n",
    "        shots_against=(\"shots_against\", \"sum\"),\n",
    "        xg_for=(\"xg_for\", \"sum\"),\n",
    "        xg_against=(\"xg_against\", \"sum\"),\n",
    "        avg_goal_diff=(\"goal_diff\", \"mean\"),\n",
    "        home_games=(\"is_home\", \"sum\")\n",
    "    )\n",
    ")\n",
    "team_season[\"goals_per_game\"] = team_season[\"goals_for\"] / team_season[\"games_played\"]\n",
    "team_season[\"goals_against_per_game\"] = team_season[\"goals_against\"] / team_season[\"games_played\"]\n",
    "\n",
    "team_season[\"shot_diff\"] = team_season[\"shots_for\"] - team_season[\"shots_against\"]\n",
    "team_season[\"xg_diff\"] = team_season[\"xg_for\"] - team_season[\"xg_against\"]\n",
    "team_season[\"win_pct\"] = team_season[\"wins\"] / team_season[\"games_played\"]\n",
    "team_season[\"loss_pct\"] = team_season[\"losses\"] / team_season[\"games_played\"]\n",
    "\n",
    "team_season\n",
    "team_season.sort_values(\"loss_pct\", ascending=False).head()\n",
    "\n",
    "home_wins = games[games['home_goals'] > games['away_goals']]\n",
    "home_wins.describe()\n",
    "'''\n",
    "# TODO: Calculate 'Home Multiplier' by comparing Home xG/60 vs Away xG/60 across the league.\n",
    "# TODO: Apply a 'Neutrality Filter' to penalize home-heavy schedules in the rankings.\n",
    "\n",
    "# --- LOGIC FOR went_ot (The Volatility Filter) ---\n",
    "# 1. Regulation Performance: Use this to isolate 'Regulation Goal Differential'.\n",
    "#    A team winning 5-0 in regulation is significantly stronger than a team\n",
    "#    winning 1-0 in OT. The former shows dominance; the latter shows a coin-flip.\n",
    "#\n",
    "# 2. 'The Paper Tiger' Check: Identify teams with high standings but high OT win rates.\n",
    "#    If a team relies on OT/Shootouts, their Power Ranking should be ADJUSTED DOWN\n",
    "#    as OT results are less repeatable than 5-on-5 play.\n",
    "#\n",
    "# 3. 'The Resilience' Factor: Boost teams with high OT Loss counts.\n",
    "#    In the standings, they look like losers (0 wins), but in reality,\n",
    "#    they are competitive enough to hold elite teams to a draw for 60 minutes.\n",
    "#\n",
    "# 4. Usage Normalization: Since OT adds extra 'toi', always use 'per 60 minutes'\n",
    "#    rates (e.g., xG/60) to ensure OT minutes don't artificially inflate total stats.\n",
    "\n",
    "# --- LOGIC FOR home_off_line (The Roster Strength Factor) ---\n",
    "# 1. Roster Depth: Compare 'first_off' vs 'second_off' xG/60.\n",
    "#    - 'One-Line Wonders': Teams with a huge drop-off in quality (e.g., 1st line 3.0 xG, 2nd line 0.5 xG).\n",
    "#    - 'Balanced Giants': Teams where both lines produce consistently.\n",
    "#    ACTION: Reward 'Balanced' teams with a higher stability score in rankings.\n",
    "#\n",
    "# 2. Situational Power: Isolate 'PP_up' (Power Play) records.\n",
    "#    - Standing might be low, but if 'PP_up' xG/60 is top 5, they are a 'Danger Team'.\n",
    "#    ACTION: Add a 'Special Teams Grade' to the final Power Ranking.\n",
    "#\n",
    "# 3. 5-on-5 Purity: Filter for 'first_off' and 'second_off' only to find 'Even-Strength' dominance.\n",
    "#    - This is the most repeatable part of hockey.\n",
    "#    ACTION: Use Even-Strength xG Differential as 50% of the total Power Ranking weight.\n",
    "#\n",
    "# 4. Tactical Matchups: Link with 'away_def_pairing' to see which lines 'crush' weaker defenders.\n",
    "#    - Identify teams that successfully hunt mismatches (e.g., first_off vs. opponent's second_def).\n",
    "\n",
    "# --- LOGIC FOR home_def_pairing (The Shutdown Metric) ---\n",
    "# 1. Shutdown Quality: Calculate 'xG Allowed per 60' for each pairing.\n",
    "#    A team's 'Defensive Rank' should be heavily weighted by the first_def unit.\n",
    "#\n",
    "# 2. Defensive Depth: Measure the 'Reliability Gap' between 1st and 2nd pairs.\n",
    "#    Teams with a strong second_def are 'Tournament Hardened' and harder to exploit.\n",
    "#\n",
    "# 3. PK Specialist Rank: Filter for 'PP_kill_dwn'.\n",
    "#    Identify teams that effectively suppress xG even when man-down.\n",
    "#    High PK efficiency is a major signal for 'Playoff Ready' power rankings.\n",
    "#\n",
    "# 4. Goal-Save Delta: Compare 'Actual Goals Allowed' vs 'xG Allowed' per pairing.\n",
    "#    If a pairing allows high xG but zero goals, the goalie is 'bailing them out'.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "home_ot = games[['home_team', 'went_ot']].rename(columns={'home_team': 'team'})\n",
    "away_ot = games[['away_team', 'went_ot']].rename(columns={'away_team': 'team'})\n",
    "\n",
    "# Combine both lists and sum the OT occurrences\n",
    "team_ot_counts = pd.concat([home_ot, away_ot]).groupby('team')['went_ot'].sum().reset_index()\n",
    "team_ot_counts.columns = ['team', 'ot_games_count']\n",
    "\n",
    "# Sort by the number of OT games\n",
    "team_ot_counts = team_ot_counts.sort_values(by='ot_games_count', ascending=False)\n",
    "print(team_ot_counts)\n",
    "team_games[\"reg_win\"] = ((team_games[\"goal_diff\"] > 0) & (team_games[\"went_ot\"] == 0)).astype(int)\n",
    "team_games[\"ot_win\"] = ((team_games[\"goal_diff\"] > 0) & (team_games[\"went_ot\"] == 1)).astype(int)\n",
    "team_games[\"ot_loss\"] = ((team_games[\"goal_diff\"] < 0) & (team_games[\"went_ot\"] == 1)).astype(int)\n",
    "team_games[\"reg_loss\"] = ((team_games[\"goal_diff\"] < 0) & (team_games[\"went_ot\"] == 0)).astype(int)\n",
    "team_season = (\n",
    "    team_games\n",
    "    .groupby(\"team\", as_index=False)\n",
    "    .agg(\n",
    "        games_played=(\"team\", \"count\"),\n",
    "        reg_wins=(\"reg_win\", \"sum\"),\n",
    "        ot_wins=(\"ot_win\", \"sum\"),\n",
    "        ot_losses=(\"ot_loss\", \"sum\"),\n",
    "        reg_losses=(\"reg_loss\", \"sum\"),\n",
    "        goals_for=(\"goals_for\", \"sum\"),\n",
    "        goals_against=(\"goals_against\", \"sum\"),\n",
    "        xg_for=(\"xg_for\", \"sum\"),\n",
    "        xg_against=(\"xg_against\", \"sum\"),\n",
    "        total_ot_games=(\"went_ot\", \"sum\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Calculate the New Metrics (The Logic Check)\n",
    "# Regulation Performance (Pure Dominance)\n",
    "team_season[\"reg_win_pct\"] = team_season[\"reg_wins\"] / team_season[\"games_played\"]\n",
    "\n",
    "# 'The Paper Tiger' Check (What % of their wins are 'coin-flips'?)\n",
    "# High ratio = Adjusted Down\n",
    "team_season[\"ot_reliance_ratio\"] = team_season[\"ot_wins\"] / (team_season[\"reg_wins\"] + team_season[\"ot_wins\"] + 1e-6)\n",
    "\n",
    "# 'The Resilience' Factor (High OT losses = Competitiveness)\n",
    "# High ratio = Adjusted Up\n",
    "team_season[\"resilience_factor\"] = team_season[\"ot_losses\"] / (\n",
    "            team_season[\"reg_losses\"] + team_season[\"ot_losses\"] + 1e-6)\n",
    "\n",
    "# 4. Usage Normalization (Per 60)\n",
    "# Assuming OT adds roughly 5 mins on average to a game\n",
    "team_season[\"total_minutes\"] = (team_season[\"games_played\"] * 60) + (team_season[\"total_ot_games\"] * 5)\n",
    "team_season[\"xg_for_per_60\"] = (team_season[\"xg_for\"] / team_season[\"total_minutes\"]) * 60\n",
    "team_season[\"xg_against_per_60\"] = (team_season[\"xg_against\"] / team_season[\"total_minutes\"]) * 60\n",
    "\n",
    "team_season.sort_values(\"reg_win_pct\", ascending=False)\n",
    "# 1. Total wins (Reg + OT) for the standard Win %\n",
    "team_games[\"total_win\"] = (team_games[\"goal_diff\"] > 0).astype(int)\n",
    "\n",
    "# 2. Updated Aggregation\n",
    "team_season = (\n",
    "    team_games\n",
    "    .groupby(\"team\", as_index=False)\n",
    "    .agg(\n",
    "        games_played=(\"team\", \"count\"),\n",
    "        total_wins=(\"total_win\", \"sum\"),  # For standard win_pct\n",
    "        reg_wins=(\"reg_win\", \"sum\"),  # For pure dominance\n",
    "        ot_wins=(\"ot_win\", \"sum\"),  # For luck factor\n",
    "        ot_losses=(\"ot_loss\", \"sum\"),  # For resilience\n",
    "        reg_losses=(\"reg_loss\", \"sum\"),  # For comparison\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Calculate the side-by-side rates\n",
    "team_season[\"win_pct\"] = team_season[\"total_wins\"] / team_season[\"games_played\"]\n",
    "team_season[\"reg_win_pct\"] = team_season[\"reg_wins\"] / team_season[\"games_played\"]\n",
    "\n",
    "# 4. Calculate the 'Deception Gap'\n",
    "team_season['deception_gap'] = team_season['win_pct'] - team_season['reg_win_pct']\n",
    "\n",
    "# Display the comparison\n",
    "print(team_season[['team', 'win_pct', 'reg_win_pct', 'deception_gap']].sort_values(by='deception_gap', ascending=False))\n",
    "\n",
    "# Create the scatter plot\n",
    "plot = sns.scatterplot(\n",
    "    data=team_season,\n",
    "    x='ot_reliance_ratio',\n",
    "    y='resilience_factor',\n",
    "    hue='reg_win_pct',\n",
    "    size='games_played',\n",
    "    palette='viridis',\n",
    "    sizes=(50, 400)\n",
    ")\n",
    "\n",
    "# Add team names as labels\n",
    "for i in range(team_season.shape[0]):\n",
    "    plt.text(\n",
    "        x=team_season.ot_reliance_ratio[i] + 0.005,\n",
    "        y=team_season.resilience_factor[i] + 0.005,\n",
    "        s=team_season.team[i],\n",
    "        fontsize=9,\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "# Add quadrants for easier analysis\n",
    "plt.axvline(team_season['ot_reliance_ratio'].mean(), color='red', linestyle='--', alpha=0.5)\n",
    "plt.axhline(team_season['resilience_factor'].mean(), color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Label the Quadrants\n",
    "plt.text(0.4, 0.8, \"Resilient Underdogs\", color='gray', fontsize=12)\n",
    "plt.text(0.4, 0.1, \"Paper Tigers\", color='gray', fontsize=12)\n",
    "\n",
    "plt.title(\"WHL Team Profiles: OT Reliance vs Resilience (Labeled)\")\n",
    "plt.xlabel(\"OT Reliance (OT Wins / Total Wins)\")\n",
    "plt.ylabel(\"Resilience Factor (OT Losses / Total Losses)\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2)\n",
    "plt.show()\n",
    "# 1. Ensure the underlying team_games has everything\n",
    "# (This assumes team_games already has goals_for, shots_for, xg_for from your earlier concat)\n",
    "\n",
    "# 2. Re-run the Master Aggregation\n",
    "team_season = (\n",
    "    team_games\n",
    "    .groupby(\"team\", as_index=False)\n",
    "    .agg(\n",
    "        games_played=(\"team\", \"count\"),\n",
    "        total_wins=(\"total_win\", \"sum\"),\n",
    "        reg_wins=(\"reg_win\", \"sum\"),\n",
    "        ot_wins=(\"ot_win\", \"sum\"),\n",
    "        ot_losses=(\"ot_loss\", \"sum\"),\n",
    "        reg_losses=(\"reg_loss\", \"sum\"),\n",
    "        shots_for=(\"shots_for\", \"sum\"),  # Added this back\n",
    "        shots_against=(\"shots_against\", \"sum\"),  # Added this back\n",
    "        xg_for=(\"xg_for\", \"sum\"),\n",
    "        xg_against=(\"xg_against\", \"sum\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Re-calculate the rates\n",
    "team_season[\"win_pct\"] = team_season[\"total_wins\"] / team_season[\"games_played\"]\n",
    "team_season[\"reg_win_pct\"] = team_season[\"reg_wins\"] / team_season[\"games_played\"]\n",
    "team_season[\"deception_gap\"] = team_season[\"win_pct\"] - team_season[\"reg_win_pct\"]\n",
    "team_season[\"xg_diff\"] = team_season[\"xg_for\"] - team_season[\"xg_against\"]\n",
    "\n",
    "# 4. Now the Corsi (Shot Share) calculation will work!\n",
    "team_season[\"corsi_for_pct\"] = team_season[\"shots_for\"] / (team_season[\"shots_for\"] + team_season[\"shots_against\"])\n",
    "# 1. Calculate the League-Wide Benchmarks (The Limits)\n",
    "corsi_mean = team_season[\"corsi_for_pct\"].mean()\n",
    "gap_mean = team_season[\"deception_gap\"].mean()\n",
    "\n",
    "# 2. Print the Threshold Report\n",
    "print(\"--- WHL MODEL CLASSIFICATION LIMITS ---\")\n",
    "print(f\"Corsi Mean (Possession Threshold): {corsi_mean:.4f}\")\n",
    "print(f\"Deception Mean (Luck Threshold):     {gap_mean:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# 3. Define the Logic\n",
    "def identify_profile(row):\n",
    "    # Quadrant 1: Low Possession, High OT Luck\n",
    "    if row[\"corsi_for_pct\"] < corsi_mean and row[\"deception_gap\"] > gap_mean:\n",
    "        return \"Double Fraud\"\n",
    "    # Quadrant 2: High Possession, Low OT Luck (Dominant)\n",
    "    if row[\"corsi_for_pct\"] > corsi_mean and row[\"deception_gap\"] < gap_mean:\n",
    "        return \"Pure Juggernaut\"\n",
    "    # Quadrant 3: High Possession, High OT Luck (Can't finish in 60)\n",
    "    if row[\"corsi_for_pct\"] > corsi_mean and row[\"deception_gap\"] > gap_mean:\n",
    "        return \"Finishing Problem\"\n",
    "    # Quadrant 4: Low Possession, Low OT Luck\n",
    "    return \"Underdog\"\n",
    "\n",
    "\n",
    "# 4. Apply and Display\n",
    "team_season[\"team_profile\"] = team_season.apply(identify_profile, axis=1)\n",
    "\n",
    "# Display results sorted by Deception Gap to highlight the Frauds\n",
    "analysis_cols = ['team', 'win_pct', 'reg_win_pct', 'deception_gap', 'corsi_for_pct', 'team_profile']\n",
    "\n",
    "print(\"Success! Data aggregated. Preview of top Corsi teams:\")\n",
    "print(team_season[['team', 'corsi_for_pct', 'deception_gap', 'team_profile']].sort_values('corsi_for_pct',\n",
    "                                                                                          ascending=True))\n",
    "a  # --- LOGIC FOR AWAY COLUMNS (Road Resilience & System Strength) ---\n",
    "# 1. Road Resilience Score: Aggregate team xG when playing as 'away_team'.\n",
    "#    - Compare 'Away xG/60' vs 'Home xG/60'.\n",
    "#    - ACTION: Teams with the smallest \"Home-Road Gap\" get a Reliability Bonus.\n",
    "#      They are 'System-Strong' and play well regardless of environment.\n",
    "#\n",
    "# 2. Defensive Opponent-Adjustment: Use away_def_pairing to 'weight' offensive success.\n",
    "#    - Scoring against an opponent's 'first_def' is worth more Power Points\n",
    "#      than scoring against their 'second_def'.\n",
    "#    - ACTION: Create a 'Difficulty-Adjusted Goal' metric.\n",
    "#\n",
    "# 3. The \"Last Change\" Penalty: On the road, teams cannot control line matchups.\n",
    "#    - If a team's 'away_off_line' (1st) still dominates while being 'hunted'\n",
    "#      by the home coach, they are a Top-Tier Juggernaut.\n",
    "#\n",
    "# 4. Data Normalization: Combine Home and Away stats into a single 'Neutral Table'.\n",
    "#    - This ensures a team's Power Ranking is based on their WHOLE season,\n",
    "#      not just a favorable home schedule.\n",
    "\n",
    "# --- LOGIC FOR GOALIE COLUMNS (The Gatekeeper Factor) ---\n",
    "# 1. GSAx (Goals Saved Above Expected): Compare 'Actual Goals Allowed' vs 'Total xG'.\n",
    "#    - Formula: GSAx = Total xG - Actual Goals.\n",
    "#    - ACTION: High GSAx = Elite Goalie. Low GSAx = Weak Link.\n",
    "#\n",
    "# 2. Standings vs. Process: Identify teams 'carried' by their goalie.\n",
    "#    - If a team wins despite being out-shot (low xG share), their rank is FRAGILE.\n",
    "#    - ACTION: Weight 'Team xG' higher than 'Actual Wins' to find sustainable power.\n",
    "#\n",
    "# 3. Goalie Split: Check if a team has a clear 'Starter' vs 'Backup'.\n",
    "#    - Does the team's Win % drop significantly when the backup goalie is in?\n",
    "#    - ACTION: Create a 'Roster Reliability' score based on the gap between goalies.\n",
    "#\n",
    "# 4. The 'Sieve' Alert: Flag teams with high xG suppression (great defense)\n",
    "#    but high Goals Against (bad goalie). These are 'Sleepers' if they swap goalies.\n",
    "# --- LOGIC FOR TOI (The Normalization Key) ---\n",
    "# 1. Rate Normalization: NEVER use raw xG or Goals for rankings.\n",
    "#    Always calculate (Stat / toi) * 3600 to get the 'Per 60' rate.\n",
    "#\n",
    "# 2. Fatigue Analysis: Track total TOI for 'first_def' and 'first_off'.\n",
    "#    Teams with extreme workloads for top units should get a 'Sustainability Penalty'\n",
    "#    in long-term power rankings.\n",
    "#\n",
    "# 3. Small Sample Filter: Ignore or down-weight lines with less than\n",
    "#    a certain threshold of total TOI (e.g., 500 seconds) to avoid 'fluke' stats.\n",
    "#\n",
    "# 4. Efficiency Mapping: Combine TOI with xG to see which lines are the\n",
    "#    most 'lethal' per minute played.\n",
    "# --- LOGIC FOR SHOTS & ASSISTS (Style & Luck Filter) ---\n",
    "# 1. Shooting Percentage: (home_goals / home_shots).\n",
    "#    - Identify 'Sustainability': If a team's shooting % is way above the league average,\n",
    "#      expect their Power Ranking to drop later (regression).\n",
    "#\n",
    "# 2. Playmaking Grade: (home_assists / home_goals).\n",
    "#    - High ratios indicate 'System Teams' with high puck movement.\n",
    "#    - Low ratios indicate 'Individualist Teams' (reliant on solo efforts/turnovers).\n",
    "#\n",
    "# 3. Chaos Generator: Identify teams with high 'Shots per 60' but low xG.\n",
    "#    - These teams play a 'dirty' gameâ€”relying on rebounds and volume rather than skill.\n",
    "#\n",
    "# 4. Assist Map: Link assists to off_line.\n",
    "#    - Does the 1st line rely on assists while the 2nd line scores solo?\n",
    "#    - ACTION: Use this to determine which line is easier to 'scout' and shut down.\n",
    "# --- LOGIC FOR PENALTIES (The Discipline & Chaos Metric) ---\n",
    "# 1. Discipline Rating: Calculate 'Penalty Minutes per 60'.\n",
    "#    - Identify teams that 'beat themselves'. A high-penalizing team\n",
    "#      should have their Power Score docked for 'Unreliability'.\n",
    "#\n",
    "# 2. Special Teams Exposure: Compare 'home_penalties' vs 'away_penalties'.\n",
    "#    - If away_penalties >> home_penalties, the team is mentally fragile on the road.\n",
    "#\n",
    "# 3. Penalty-Adjusted xG: Create a 'Clean-Play xG' by filtering out records\n",
    "#    where home_penalty == 1. This shows how good a team is when playing fair.\n",
    "#\n",
    "# 4. The 'Instigator' Factor: Does a team draw more penalties than they take?\n",
    "#    - Compare 'home_penalties' vs 'away_penalties' in the same game.\n",
    "#    - Teams that 'draw' penalties have high 'Functional Aggression'.\n",
    "--- LOGIC\n",
    "FOR\n",
    "went_ot(The\n",
    "Volatility\n",
    "Filter) ---\n",
    "# 1. Regulation Performance: Use this to isolate 'Regulation Goal Differential'.\n",
    "#    A team winning 5-0 in regulation is significantly stronger than a team\n",
    "#    winning 1-0 in OT. The former shows dominance; the latter shows a coin-flip.\n",
    "#\n",
    "# 2. 'The Paper Tiger' Check: Identify teams with high standings but high OT win rates.\n",
    "#    If a team relies on OT/Shootouts, their Power Ranking should be ADJUSTED DOWN\n",
    "#    as OT results are less repeatable than 5-on-5 play.\n",
    "#\n",
    "# 3. 'The Resilience' Factor: Boost teams with high OT Loss counts.\n",
    "#    In the standings, they look like losers (0 wins), but in reality,\n",
    "#    they are competitive enough to hold elite teams to a draw for 60 minutes.\n",
    "#\n",
    "# 4. Usage Normalization: Since OT adds extra 'toi', always use 'per 60 minutes'\n",
    "#    rates (e.g., xG/60) to ensure OT minutes don't artificially inflate total stats.\n",
    "\n",
    "--- LOGIC\n",
    "FOR\n",
    "home_off_line(The\n",
    "Roster\n",
    "Strength\n",
    "Factor) ---\n",
    "# 1. Roster Depth: Compare 'first_off' vs 'second_off' xG/60.\n",
    "#    - 'One-Line Wonders': Teams with a huge drop-off in quality (e.g., 1st line 3.0 xG, 2nd line 0.5 xG).\n",
    "#    - 'Balanced Giants': Teams where both lines produce consistently.\n",
    "#    ACTION: Reward 'Balanced' teams with a higher stability score in rankings.\n",
    "#\n",
    "# 2. Situational Power: Isolate 'PP_up' (Power Play) records.\n",
    "#    - Standing might be low, but if 'PP_up' xG/60 is top 5, they are a 'Danger Team'.\n",
    "#    ACTION: Add a 'Special Teams Grade' to the final Power Ranking.\n",
    "#\n",
    "# 3. 5-on-5 Purity: Filter for 'first_off' and 'second_off' only to find 'Even-Strength' dominance.\n",
    "#    - This is the most repeatable part of hockey.\n",
    "#    ACTION: Use Even-Strength xG Differential as 50% of the total Power Ranking weight.\n",
    "#\n",
    "# 4. Tactical Matchups: Link with 'away_def_pairing' to see which lines 'crush' weaker defenders.\n",
    "#    - Identify teams that successfully hunt mismatches (e.g., first_off vs. opponent's second_def).\n",
    "# --- LOGIC FOR AWAY COLUMNS (Road Resilience & System Strength) ---\n",
    "# 1. Road Resilience Score: Aggregate team xG when playing as 'away_team'.\n",
    "#    - Compare 'Away xG/60' vs 'Home xG/60'.\n",
    "#    - ACTION: Teams with the smallest \"Home-Road Gap\" get a Reliability Bonus.\n",
    "#      They are 'System-Strong' and play well regardless of environment.\n",
    "#\n",
    "# 2. Defensive Opponent-Adjustment: Use away_def_pairing to 'weight' offensive success.\n",
    "#    - Scoring against an opponent's 'first_def' is worth more Power Points\n",
    "#      than scoring against their 'second_def'.\n",
    "#    - ACTION: Create a 'Difficulty-Adjusted Goal' metric.\n",
    "#\n",
    "# 3. The \"Last Change\" Penalty: On the road, teams cannot control line matchups.\n",
    "#    - If a team's 'away_off_line' (1st) still dominates while being 'hunted'\n",
    "#      by the home coach, they are a Top-Tier Juggernaut.\n",
    "#\n",
    "# 4. Data Normalization: Combine Home and Away stats into a single 'Neutral Table'.\n",
    "#    - This ensures a team's Power Ranking is based on their WHOLE season,\n",
    "#      not just a favorable home schedule.\n",
    "# 1. Calculate xG/60 for each offensive line\n",
    "line_stats = df.groupby(['home_team', 'home_off_line']).agg(\n",
    "    total_xg=('home_xg', 'sum'),\n",
    "    total_toi=('toi', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "line_stats['xg_60'] = (line_stats['total_xg'] / line_stats['total_toi']) * 60\n",
    "\n",
    "# 2. Pivot to compare lines\n",
    "roster_pivot = line_stats.pivot(index='home_team', columns='home_off_line', values='xg_60')\n",
    "\n",
    "# 3. Calculate 'Purity' (Average of top 2 lines) and 'Stability' (The Gap)\n",
    "roster_pivot['five_on_five_purity'] = (roster_pivot['first_off'] + roster_pivot['second_off']) / 2\n",
    "roster_pivot['roster_stability_ratio'] = roster_pivot['first_off'] / (roster_pivot['second_off'] + 1e-6)\n",
    "\n",
    "print(\"--- PILLAR 1: 5-on-5 PURITY & STABILITY ---\")\n",
    "print(roster_pivot[['five_on_five_purity', 'roster_stability_ratio']].sort_values('five_on_five_purity',\n",
    "                                                                                  ascending=False).head())\n",
    "# --- PRETEXT: AUTO-CALIBRATING ROSTER DEPTH ---\n",
    "# Instead of guessing that a 1.5 ratio is 'Top Heavy', this code\n",
    "# looks at the entire league's distribution and labels the\n",
    "# outliers. This ensures we ALWAYS find the most top-heavy teams.\n",
    "\n",
    "# 1. Calculate the actual median ratio for the league\n",
    "median_stability = roster_pivot['roster_stability_ratio'].median()\n",
    "median_purity = roster_pivot['five_on_five_purity'].median()\n",
    "\n",
    "print(f\"League Average Stability Ratio: {median_stability:.2f}\")\n",
    "\n",
    "\n",
    "# 2. Re-classify using Relative Thresholds\n",
    "def classify_offense_dynamic(row):\n",
    "    # Above average production?\n",
    "    is_high_scoring = row['five_on_five_purity'] > median_purity\n",
    "    # More top-heavy than the average team?\n",
    "    is_top_heavy = row['roster_stability_ratio'] > median_stability\n",
    "\n",
    "    if is_high_scoring:\n",
    "        return \"Balanced Giant\" if not is_top_heavy else \"One-Line Wonder\"\n",
    "    else:\n",
    "        return \"Deep but Weak\" if not is_top_heavy else \"Top-Heavy Underdog\"\n",
    "\n",
    "\n",
    "roster_pivot['off_identity'] = roster_pivot.apply(classify_offense_dynamic, axis=1)\n",
    "\n",
    "# 3. Check the distribution\n",
    "print(roster_pivot['off_identity'].value_counts())\n",
    "\n",
    "# 1. Calculate medians for dynamic labeling\n",
    "# We use the median so that exactly half the league is 'High Scoring'\n",
    "# and half is 'Top Heavy' (relatively speaking).\n",
    "median_purity = roster_pivot['five_on_five_purity'].median()\n",
    "median_stability = roster_pivot['roster_stability_ratio'].median()\n",
    "\n",
    "\n",
    "# 2. Engineering the Label Column\n",
    "def classify_offense_dynamic(row):\n",
    "    # Above average production?\n",
    "    is_high_scoring = row['five_on_five_purity'] > median_purity\n",
    "    # More top-heavy than the average team?\n",
    "    is_top_heavy = row['roster_stability_ratio'] > median_stability\n",
    "\n",
    "    if is_high_scoring:\n",
    "        # High scoring + Balanced depth\n",
    "        if not is_top_heavy:\n",
    "            return \"Balanced Giant\"\n",
    "        # High scoring + Reliance on 1st line\n",
    "        else:\n",
    "            return \"One-Line Wonder\"\n",
    "    else:\n",
    "        # Low scoring + Balanced depth\n",
    "        if not is_top_heavy:\n",
    "            return \"Deep but Weak\"\n",
    "        # Low scoring + Reliance on 1st line\n",
    "        else:\n",
    "            return \"Top-Heavy Underdog\"\n",
    "\n",
    "\n",
    "# Apply the labels to a new feature column\n",
    "roster_pivot['off_identity'] = roster_pivot.apply(classify_offense_dynamic, axis=1)\n",
    "\n",
    "# 3. Print the engineered feature set\n",
    "print(\"--- OFFENSIVE FEATURE ENGINEERING: TEXT LABELS ---\")\n",
    "print(roster_pivot[['five_on_five_purity', 'roster_stability_ratio', 'off_identity']].sort_values('five_on_five_purity',\n",
    "                                                                                                  ascending=False))\n",
    "# --- FEATURE ENGINEERING: DEFENSIVE & GOALIE IDENTITY ---\n",
    "\n",
    "# 1. Aggregate Defensive Data\n",
    "# We focus on 'first_def' as they face the highest quality competition\n",
    "def_stats = df.groupby(['home_team', 'home_def_pairing']).agg(\n",
    "    xg_against=('away_xg', 'sum'),\n",
    "    goals_against=('away_goals', 'sum'),\n",
    "    total_toi=('toi', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# 2. Calculate Normalized Rates\n",
    "def_stats['xGA_60'] = (def_stats['xg_against'] / def_stats['total_toi']) * 60\n",
    "def_stats['actual_GA_60'] = (def_stats['goals_against'] / def_stats['total_toi']) * 60\n",
    "\n",
    "# 3. Engineer the 'Goalie Factor'\n",
    "# (Actual - Expected). Negative means the goalie saved more than expected.\n",
    "def_stats['goalie_factor'] = def_stats['actual_GA_60'] - def_stats['xGA_60']\n",
    "\n",
    "# 4. Set Thresholds for Labeling\n",
    "shutdown_unit = def_stats[def_stats['home_def_pairing'] == 'first_def'].set_index('home_team')\n",
    "median_xGA = shutdown_unit['xGA_60'].median()\n",
    "\n",
    "\n",
    "# 5. Engineering the Text Label Column\n",
    "def classify_goalie_performance(row):\n",
    "    # System Check\n",
    "    is_steel_wall = row['xGA_60'] < median_xGA\n",
    "\n",
    "    # Goalie Check\n",
    "    if row['goalie_factor'] < -0.2:\n",
    "        goalie_label = \"Goalie Hero\"\n",
    "    elif row['goalie_factor'] > 0.2:\n",
    "        goalie_label = \"Goalie Vulnerable\"\n",
    "    else:\n",
    "        goalie_label = \"Standard Support\"\n",
    "\n",
    "    system_label = \"Steel Wall\" if is_steel_wall else \"Leaky System\"\n",
    "    return f\"{system_label} ({goalie_label})\"\n",
    "\n",
    "\n",
    "shutdown_unit['def_identity'] = shutdown_unit.apply(classify_goalie_performance, axis=1)\n",
    "\n",
    "# 6. Display the Results\n",
    "print(\"--- DEFENSIVE FEATURE ENGINEERING: GOALIE LABELS ---\")\n",
    "print(shutdown_unit[['xGA_60', 'goalie_factor', 'def_identity']].sort_values('goalie_factor'))\n",
    "# --- FEATURE ENGINEERING: THE TEAM DNA SYNTHESIS ---\n",
    "\n",
    "# 1. Merge the Offensive and Defensive identities\n",
    "# We join the two pivoted/engineered dataframes on the team name\n",
    "team_dna_report = roster_pivot[['off_identity', 'five_on_five_purity']].merge(\n",
    "    shutdown_unit[['def_identity', 'xGA_60', 'goalie_factor']],\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Engineer the 'Strategic Archetype' Label\n",
    "# This is a high-level feature for executive summaries\n",
    "def label_archetype(row):\n",
    "    if row['off_identity'] == \"Balanced Giant\" and \"Steel Wall\" in row['def_identity']:\n",
    "        return \"Complete Contender\"\n",
    "    elif row['off_identity'] == \"One-Line Wonder\" and \"Goalie Hero\" in row['def_identity']:\n",
    "        return \"The Glass House (Star-Dependent)\"\n",
    "    elif \"Leaky System\" in row['def_identity'] and row['off_identity'] == \"One-Line Wonder\":\n",
    "        return \"Critical Risk\"\n",
    "    elif \"Steel Wall\" in row['def_identity'] and row['off_identity'] == \"Deep but Weak\":\n",
    "        return \"The Defensive Specialist\"\n",
    "    else:\n",
    "        return \"The Wildcard\"\n",
    "\n",
    "\n",
    "team_dna_report['strategic_archetype'] = team_dna_report.apply(label_archetype, axis=1)\n",
    "\n",
    "# 1. Merge Offensive Features and Defensive Features into one row per team\n",
    "# We use 'inner' to ensure we only keep teams that have both offensive and defensive data\n",
    "team_master_features = roster_pivot.merge(\n",
    "    shutdown_unit,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=('_off', '_def')\n",
    ")\n",
    "\n",
    "# 2. Select and Rename the most important engineered columns for clarity\n",
    "final_features = team_master_features[[\n",
    "    'off_identity',  # Balanced Giant, One-Line Wonder, etc.\n",
    "    'def_identity',  # Steel Wall (Hero), Leaky (Vulnerable), etc.\n",
    "    'five_on_five_purity',\n",
    "    'xGA_60',\n",
    "    'goalie_factor'\n",
    "]]\n",
    "\n",
    "# 3. Print the results - Now everything is on the SAME LINE\n",
    "print(\"--- CONSOLIDATED TEAM FEATURES ---\")\n",
    "final_features.sort_values('five_on_five_purity', ascending=False)\n",
    "# 1. Unifying the Pillars\n",
    "# We join 'roster_pivot' (Offense) and 'shutdown_unit' (Defense)\n",
    "# Since both are indexed by team name, they will align perfectly on the same line.\n",
    "team_features_df = roster_pivot[['off_identity', 'five_on_five_purity', 'roster_stability_ratio']].join(\n",
    "    shutdown_unit[['def_identity', 'xGA_60', 'goalie_factor']]\n",
    ")\n",
    "\n",
    "# 2. Engineering the 'Master Profile' Label\n",
    "# This creates a single text string summarizing the whole team identity\n",
    "team_features_df['team_profile'] = (\n",
    "        team_features_df['off_identity'] + \" | \" + team_features_df['def_identity']\n",
    ")\n",
    "\n",
    "# 3. Handle any missing data (NaNs) just in case\n",
    "team_features_df = team_features_df.fillna(\"Unknown/Incomplete\")\n",
    "\n",
    "# 4. Display the result in Jupyter\n",
    "print(\"--- MASTER FEATURE MATRIX DEFINED ---\")\n",
    "display(team_features_df.head())\n",
    "# 1. Aggregate Special Teams Performance\n",
    "special_stats = df.groupby(['home_team', 'home_off_line']).agg(\n",
    "    pp_xg=('home_xg', 'sum'),\n",
    "    pp_toi=('toi', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Filter for just the Power Play units\n",
    "pp_units = special_stats[special_stats['home_off_line'] == 'PP_up'].copy()\n",
    "pp_units['pp_xg_60'] = (pp_units['pp_xg'] / pp_units['pp_toi']) * 60\n",
    "\n",
    "# 2. Join this back to your Master Matrix\n",
    "team_features_df = team_features_df.join(pp_units.set_index('home_team')[['pp_xg_60']])\n",
    "\n",
    "# 3. Labeling the Special Teams Specialist\n",
    "pp_median = team_features_df['pp_xg_60'].median()\n",
    "\n",
    "\n",
    "def label_special_teams(row):\n",
    "    if row['pp_xg_60'] > team_features_df['pp_xg_60'].quantile(0.75):\n",
    "        return \"Special Teams Specialist\"\n",
    "    elif row['pp_xg_60'] < team_features_df['pp_xg_60'].quantile(0.25):\n",
    "        return \"Special Teams Liability\"\n",
    "    else:\n",
    "        return \"Standard Unit\"\n",
    "\n",
    "\n",
    "team_features_df['st_identity'] = team_features_df.apply(label_special_teams, axis=1)\n",
    "\n",
    "# 4. Display the updated Master Matrix\n",
    "team_features_df[['off_identity', 'def_identity', 'st_identity', 'pp_xg_60']].sort_values('pp_xg_60', ascending=False)"
   ],
   "id": "30aff8c11dd7a6eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore, rankdata\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel('./datasci/cleanedup/whl_2025_base.xlsx')\n",
    "\n",
    "# --- Data Processing (Team-Game Level) ---\n",
    "home_df = df[['game_id', 'home_team', 'home_goals', 'away_goals', 'home_xg', 'away_xg', 'home_shots', 'away_shots',\n",
    "              'home_penalty_minutes', 'went_ot']].copy()\n",
    "home_df.columns = ['game_id', 'team', 'gf', 'ga', 'xgf', 'xga', 'sf', 'sa', 'pim', 'is_ot']\n",
    "home_df['is_home'] = 1\n",
    "# Simple Points Calculation (2 for win, 1 for OT loss? We'll assume Win=2)\n",
    "home_df['pts'] = np.where(home_df['gf'] > home_df['ga'], 2, np.where(home_df['is_ot'] == 1, 1, 0))\n",
    "\n",
    "away_df = df[['game_id', 'away_team', 'away_goals', 'home_goals', 'away_xg', 'home_xg', 'away_shots', 'home_shots',\n",
    "              'away_penalty_minutes', 'went_ot']].copy()\n",
    "away_df.columns = ['game_id', 'team', 'gf', 'ga', 'xgf', 'xga', 'sf', 'sa', 'pim', 'is_ot']\n",
    "away_df['is_home'] = 0\n",
    "away_df['pts'] = np.where(away_df['gf'] > away_df['ga'], 2, np.where(away_df['is_ot'] == 1, 1, 0))\n",
    "\n",
    "team_games = pd.concat([home_df, away_df], ignore_index=True)\n",
    "\n",
    "# --- Aggregations & Metrics ---\n",
    "stats = team_games.groupby('team').agg(\n",
    "    gp=('game_id', 'count'),\n",
    "    gf=('gf', 'sum'),\n",
    "    ga=('ga', 'sum'),\n",
    "    xgf=('xgf', 'sum'),\n",
    "    xga=('xga', 'sum'),\n",
    "    pts=('pts', 'sum'),\n",
    "    xga_var=('xga', 'var')  # Variance of Expected Goals Against (Consistency Proxy)\n",
    ").reset_index()\n",
    "\n",
    "# 1. The Shutdown Metric (Defense)\n",
    "stats['xGA_per_GP'] = stats['xga'] / stats['gp']\n",
    "stats['Def_Consistency'] = stats['xga_var']  # Lower is better\n",
    "\n",
    "# 2. The Gatekeeper Factor (Goaltending)\n",
    "stats['GSAx'] = stats['xga'] - stats['ga']\n",
    "stats['PTS_Pct'] = stats['pts'] / (stats['gp'] * 2)\n",
    "stats['xG_Share'] = stats['xgf'] / (stats['xgf'] + stats['xga'])\n",
    "stats['Sustain_Diff'] = stats['PTS_Pct'] - stats['xG_Share']\n",
    "\n",
    "\n",
    "# Sustain_Diff > 0: Overperforming (Goalie Saved Them?)\n",
    "# Sustain_Diff < 0: Underperforming (Goalied?)\n",
    "\n",
    "# --- Normalization & Ranking ---\n",
    "def normalize(series, invert=False):\n",
    "    if invert:\n",
    "        return 1 - ((series - series.min()) / (series.max() - series.min()))\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "\n",
    "# Defense Score (Higher is better)\n",
    "# Low xGA is good (Invert)\n",
    "# Low Variance is good (Invert)\n",
    "stats['Score_Def'] = (normalize(stats['xGA_per_GP'], invert=True) * 0.7) + (\n",
    "            normalize(stats['Def_Consistency'], invert=True) * 0.3)\n",
    "\n",
    "# Goalie Score (Higher is better)\n",
    "# High GSAx is good\n",
    "# High Sustain Diff? Actually we want sustainable power.\n",
    "# The user said: \"High GSAx = Elite\". \"If win despite being outshot... Rank is FRAGILE\".\n",
    "# So we reward GSAx, but maybe penalize extreme reliance on it?\n",
    "# Request: \"Weight Team xG higher than Actual Wins\".\n",
    "# Let's stick to GSAx as the core \"Gatekeeper\" quality metric.\n",
    "stats['Score_Goalie'] = normalize(stats['GSAx'])\n",
    "\n",
    "# Final Ranking (50/50 Split)\n",
    "stats['PowerScore'] = (stats['Score_Def'] * 0.5 + stats['Score_Goalie'] * 0.5) * 100\n",
    "stats['Rank'] = stats['PowerScore'].rank(ascending=False).astype(int)\n",
    "stats = stats.sort_values('Rank')\n",
    "\n",
    "# --- The \"Sieve\" Alert Logic ---\n",
    "# Top 33% Defense (Low xGA) AND Bottom 33% Goaltending (Low GSAx)\n",
    "xga_threshold = stats['xGA_per_GP'].quantile(0.33)\n",
    "gsax_threshold = stats['GSAx'].quantile(0.33)\n",
    "\n",
    "\n",
    "def sieves(row):\n",
    "    if row['xGA_per_GP'] <= xga_threshold and row['GSAx'] <= gsax_threshold:\n",
    "        return 'SIEVE ALERT (Good Def/Bad Goalie)'\n",
    "    if row['GSAx'] >= stats['GSAx'].quantile(0.90):\n",
    "        return 'ELITE GOALIE'\n",
    "    if row['xGA_per_GP'] <= xga_threshold:\n",
    "        return 'ELITE DEFENSE'\n",
    "    return '-'\n",
    "\n",
    "\n",
    "stats['Status'] = stats.apply(sieves, axis=1)\n",
    "\n",
    "# --- Output ---\n",
    "cols = ['Rank', 'team', 'PowerScore', 'Status', 'xGA_per_GP', 'GSAx', 'Sustain_Diff']\n",
    "print(stats[cols].to_string(index=False, float_format='%.2f'))\n",
    "\n",
    "# --- Visuals ---\n",
    "plt.style.use('dark_background')\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Quadrant Plot: Defense Quality (xGA/GP) vs Goalie Performance (GSAx)\n",
    "# Note: xGA/GP is better when LOWER. So we invert X axis or interpret left as good.\n",
    "sns.scatterplot(\n",
    "    data=stats,\n",
    "    x='xGA_per_GP',\n",
    "    y='GSAx',\n",
    "    hue='Status',\n",
    "    style='Status',\n",
    "    s=150,\n",
    "    palette='viridis'\n",
    ")\n",
    "\n",
    "# Invert X axis so Right = Better Defense? Or Left = Better?\n",
    "# Standard is Left = Lower xGA = Better.\n",
    "plt.gca().invert_xaxis()\n",
    "\n",
    "for i, row in stats.iterrows():\n",
    "    plt.text(row['xGA_per_GP'], row['GSAx'] + 0.5, row['team'], fontsize=8, color='white')\n",
    "\n",
    "plt.title('The Shutdown & Gatekeeper Map', fontsize=16)\n",
    "plt.xlabel('Defense Quality (xGA per Game) --> Better', fontsize=12)\n",
    "plt.ylabel('Goalie Performance (GSAx) Better -->', fontsize=12)\n",
    "plt.axvline(stats['xGA_per_GP'].mean(), color='gray', linestyle='--')\n",
    "plt.axhline(stats['GSAx'].mean(), color='gray', linestyle='--')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- LOGIC FOR home_def_pairing (The Shutdown Metric) ---\n",
    "# 1. Shutdown Quality: Calculate 'xG Allowed per 60' for each pairing.\n",
    "#    A team's 'Defensive Rank' should be heavily weighted by the first_def unit.\n",
    "#\n",
    "# 2. Defensive Depth: Measure the 'Reliability Gap' between 1st and 2nd pairs.\n",
    "#    Teams with a strong second_def are 'Tournament Hardened' and harder to exploit.\n",
    "#\n",
    "# 3. PK Specialist Rank: Filter for 'PP_kill_dwn'.\n",
    "#    Identify teams that effectively suppress xG even when man-down.\n",
    "#    High PK efficiency is a major signal for 'Playoff Ready' power rankings.\n",
    "#\n",
    "# 4. Goal-Save Delta: Compare 'Actual Goals Allowed' vs 'xG Allowed' per pairing.\n",
    "#    If a pairing allows high xG but zero goals, the goalie is 'bailing them out'.\n",
    "# --- LOGIC FOR GOALIE COLUMNS (The Gatekeeper Factor) ---\n",
    "# 1. GSAx (Goals Saved Above Expected): Compare 'Actual Goals Allowed' vs 'Total xG'.\n",
    "#    - Formula: GSAx = Total xG - Actual Goals.\n",
    "#    - ACTION: High GSAx = Elite Goalie. Low GSAx = Weak Link.\n",
    "#\n",
    "# 2. Standings vs. Process: Identify teams 'carried' by their goalie.\n",
    "#    - If a team wins despite being out-shot (low xG share), their rank is FRAGILE.\n",
    "#    - ACTION: Weight 'Team xG' higher than 'Actual Wins' to find sustainable power.\n",
    "#\n",
    "# 3. Goalie Split: Check if a team has a clear 'Starter' vs 'Backup'.\n",
    "#    - Does the team's Win % drop significantly when the backup goalie is in?\n",
    "#    - ACTION: Create a 'Roster Reliability' score based on the gap between goalies.\n",
    "FREAKY\n",
    "DIDDY\n",
    "ARMAAN\n",
    "GUHA\n",
    "# 4. The 'Sieve' Alert: Flag teams with high xG suppression (great defense)\n",
    "#    but high Goals Against (bad goalie). These are 'Sleepers' if they swap goalies.,\n",
    "#      not just a favorable home schedule."
   ],
   "id": "b37de9b5043bd286"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.DataFrame(pd.read_excel('./datasci/cleanedup/whl_2025_base.xlsx'))\n",
    "df.head()\n",
    "\n",
    "'''\n",
    "IDENTIFIERS:\n",
    "- game_id\n",
    "- record_id\n",
    "\n",
    "ENTITIES:\n",
    "- home_team\n",
    "- away_team\n",
    "- home_goalie\n",
    "- away_goalie\n",
    "\n",
    "CONTEXT:\n",
    "- home_off_line\n",
    "- away_off_line\n",
    "- home_def_pairing\n",
    "- away_def_pairing\n",
    "- went_ot\n",
    "\n",
    "OUTCOMES:\n",
    "- home_goals\n",
    "- away_goals\n",
    "- home_shots\n",
    "- away_shots\n",
    "- home_penalties_committed\n",
    "- away_penalties_committed\n",
    "\n",
    "DERIVED METRICS:\n",
    "- home_xg\n",
    "- away_xg\n",
    "- home_max_xg\n",
    "- away_max_xg\n",
    "'''\n",
    "sum_cols = [\n",
    "    \"home_goals\", \"away_goals\",\n",
    "    \"home_shots\", \"away_shots\",\n",
    "    \"home_xg\", \"away_xg\",\n",
    "    \"home_assists\", \"away_assists\",\n",
    "    \"home_penalties_committed\", \"away_penalties_committed\",\n",
    "    \"home_penalty_minutes\", \"away_penalty_minutes\",\n",
    "    \"toi\",\n",
    "]\n",
    "first_cols = [\n",
    "    \"home_team\",\n",
    "    \"away_team\",\n",
    "    \"went_ot\"\n",
    "]\n",
    "agg_dict = {}\n",
    "\n",
    "for col in sum_cols:\n",
    "    agg_dict[col] = \"sum\"\n",
    "\n",
    "for col in first_cols:\n",
    "    agg_dict[col] = \"first\"\n",
    "games = (\n",
    "    df\n",
    "    .groupby(\"game_id\", as_index=False)\n",
    "    .agg(agg_dict)\n",
    ")\n",
    "games.shape\n",
    "games[\"home_score\"] = games[\"home_goals\"]\n",
    "games[\"away_score\"] = games[\"away_goals\"]\n",
    "\n",
    "games[\"goal_diff\"] = games[\"home_score\"] - games[\"away_score\"]\n",
    "games[\"total_goals\"] = games[\"home_score\"] + games[\"away_score\"]\n",
    "\n",
    "games[\"shot_diff\"] = games[\"home_shots\"] - games[\"away_shots\"]\n",
    "games[\"total_shots\"] = games[\"home_shots\"] + games[\"away_shots\"]\n",
    "games[\"total_toi\"] = games[\"toi\"]\n",
    "\n",
    "games\n",
    "\n",
    "home_games = games.copy()\n",
    "\n",
    "home_games[\"team\"] = home_games[\"home_team\"]\n",
    "home_games[\"opponent\"] = home_games[\"away_team\"]\n",
    "\n",
    "home_games[\"goals_for\"] = home_games[\"home_score\"]\n",
    "home_games[\"goals_against\"] = home_games[\"away_score\"]\n",
    "\n",
    "home_games[\"shots_for\"] = home_games[\"home_shots\"]\n",
    "home_games[\"shots_against\"] = home_games[\"away_shots\"]\n",
    "\n",
    "home_games[\"xg_for\"] = home_games[\"home_xg\"]\n",
    "home_games[\"xg_against\"] = home_games[\"away_xg\"]\n",
    "\n",
    "home_games[\"is_home\"] = 1\n",
    "away_games = games.copy()\n",
    "\n",
    "away_games[\"team\"] = away_games[\"away_team\"]\n",
    "away_games[\"opponent\"] = away_games[\"home_team\"]\n",
    "\n",
    "away_games[\"goals_for\"] = away_games[\"away_score\"]\n",
    "away_games[\"goals_against\"] = away_games[\"home_score\"]\n",
    "\n",
    "away_games[\"shots_for\"] = away_games[\"away_shots\"]\n",
    "away_games[\"shots_against\"] = away_games[\"home_shots\"]\n",
    "\n",
    "away_games[\"xg_for\"] = away_games[\"away_xg\"]\n",
    "away_games[\"xg_against\"] = away_games[\"home_xg\"]\n",
    "away_games[\"is_home\"] = 0\n",
    "\n",
    "# --- LOGIC FOR TOI (The Normalization Key) ---\n",
    "# 1. Rate Normalization: NEVER use raw xG or Goals for rankings.\n",
    "#    Always calculate (Stat / toi) * 3600 to get the 'Per 60' rate.\n",
    "#\n",
    "# 2. Fatigue Analysis: Track total TOI for 'first_def' and 'first_off'.\n",
    "#    Teams with extreme workloads for top units should get a 'Sustainability Penalty'\n",
    "#    in long-term power rankings.\n",
    "#\n",
    "# 3. Small Sample Filter: Ignore or down-weight lines with less than\n",
    "#    a certain threshold of total TOI (e.g., 500 seconds) to avoid 'fluke' stats.\n",
    "#\n",
    "# 4. Efficiency Mapping: Combine TOI with xG to see which lines are the\n",
    "#    most 'lethal' per minute played.\n",
    "# --- LOGIC FOR SHOTS & ASSISTS (Style & Luck Filter) ---\n",
    "# 1. Shooting Percentage: (home_goals / home_shots).\n",
    "#    - Identify 'Sustainability': If a team's shooting % is way above the league average,\n",
    "#      expect their Power Ranking to drop later (regression).\n",
    "#\n",
    "# 2. Playmaking Grade: (home_assists / home_goals).\n",
    "#    - High ratios indicate 'System Teams' with high puck movement.\n",
    "#    - Low ratios indicate 'Individualist Teams' (reliant on solo efforts/turnovers).\n",
    "#\n",
    "# 3. Chaos Generator: Identify teams with high 'Shots per 60' but low xG.\n",
    "#    - These teams play a 'dirty' gameâ€”relying on rebounds and volume rather than skill.\n",
    "#\n",
    "# 4. Assist Map: Link assists to off_line.\n",
    "#    - Does the 1st line rely on assists while the 2nd line scores solo?\n",
    "#    - ACTION: Use this to determine which line is easier to 'scout' and shut down.\n",
    "# --- LOGIC FOR PENALTIES (The Discipline & Chaos Metric) ---\n",
    "# 1. Discipline Rating: Calculate 'Penalty Minutes per 60'.\n",
    "#    - Identify teams that 'beat themselves'. A high-penalizing team\n",
    "#      should have their Power Score docked for 'Unreliability'.\n",
    "#\n",
    "# 2. Special Teams Exposure: Compare 'home_penalties' vs 'away_penalties'.\n",
    "#    - If away_penalties >> home_penalties, the team is mentally fragile on the road.\n",
    "#\n",
    "# 3. Penalty-Adjusted xG: Create a 'Clean-Play xG' by filtering out records\n",
    "#    where home_penalty == 1. This shows how good a team is when playing fair.\n",
    "#\n",
    "# 4. The 'Instigator' Factor: Does a team draw more penalties than they take?\n",
    "#    - Compare 'home_penalties' vs 'away_penalties' in the same game.\n",
    "#    - Teams that 'draw' penalties have high 'Functional Aggression'.\n",
    "team_games = pd.concat([home_games, away_games], ignore_index=True)\n",
    "team_games[\"goal_diff\"] = team_games[\"goals_for\"] - team_games[\"goals_against\"]\n",
    "\n",
    "team_games[\"win\"] = (team_games[\"goal_diff\"] > 0).astype(int)\n",
    "team_games[\"loss\"] = (team_games[\"goal_diff\"] < 0).astype(int)\n",
    "team_season = (\n",
    "    team_games\n",
    "    .groupby(\"team\", as_index=False)\n",
    "    .agg(\n",
    "        games_played=(\"team\", \"count\"),\n",
    "        wins=(\"win\", \"sum\"),\n",
    "        losses=(\"loss\", \"sum\"),\n",
    "        goals_for=(\"goals_for\", \"sum\"),\n",
    "        goals_against=(\"goals_against\", \"sum\"),\n",
    "        shots_for=(\"shots_for\", \"sum\"),\n",
    "        shots_against=(\"shots_against\", \"sum\"),\n",
    "        xg_for=(\"xg_for\", \"sum\"),\n",
    "        xg_against=(\"xg_against\", \"sum\"),\n",
    "        avg_goal_diff=(\"goal_diff\", \"mean\"),\n",
    "        home_games=(\"is_home\", \"sum\"),\n",
    "        toi=(\"toi\", \"sum\"),\n",
    "    ))\n",
    "team_season[\"goals_per_game\"] = team_season[\"goals_for\"] / team_season[\"games_played\"]\n",
    "team_season[\"goals_against_per_game\"] = team_season[\"goals_against\"] / team_season[\"games_played\"]\n",
    "\n",
    "team_season[\"shot_diff\"] = team_season[\"shots_for\"] - team_season[\"shots_against\"]\n",
    "team_season[\"xg_diff\"] = team_season[\"xg_for\"] - team_season[\"xg_against\"]\n",
    "team_season[\"win_pct\"] = team_season[\"wins\"] / team_season[\"games_played\"]\n",
    "team_season[\"loss_pct\"] = team_season[\"losses\"] / team_season[\"games_played\"]\n",
    "team_season\n",
    "\n",
    "# Home offensive line TOI\n",
    "home_line_toi = (\n",
    "    df\n",
    "    .groupby([\"home_team\", \"home_off_line\"], as_index=False)\n",
    "    .agg(\n",
    "        total_toi=(\"toi\", \"sum\"),\n",
    "        games=(\"game_id\", \"nunique\")\n",
    "    )\n",
    "    .rename(columns={\n",
    "        \"home_team\": \"team\",\n",
    "        \"home_off_line\": \"off_line\"\n",
    "    })\n",
    ")\n",
    "\n",
    "home_line_toi[\"side\"] = \"home\"\n",
    "\n",
    "# Away offensive line TOI\n",
    "away_line_toi = (\n",
    "    df\n",
    "    .groupby([\"away_team\", \"away_off_line\"], as_index=False)\n",
    "    .agg(\n",
    "        total_toi=(\"toi\", \"sum\"),\n",
    "        games=(\"game_id\", \"nunique\")\n",
    "    )\n",
    "    .rename(columns={\n",
    "        \"away_team\": \"team\",\n",
    "        \"away_off_line\": \"off_line\"\n",
    "    })\n",
    ")\n",
    "\n",
    "away_line_toi[\"side\"] = \"away\"\n",
    "\n",
    "line_toi = pd.concat(\n",
    "    [home_line_toi, away_line_toi],\n",
    "    ignore_index=True\n",
    ")\n",
    "line_toi_total = (\n",
    "    line_toi\n",
    "    .groupby([\"team\", \"off_line\"], as_index=False)\n",
    "    .agg(\n",
    "        total_toi=(\"total_toi\", \"sum\"),\n",
    "        games=(\"games\", \"sum\")\n",
    "    )\n",
    ")\n",
    "print(line_toi_total.head(128))\n",
    "\n",
    "home_lines = (\n",
    "    df\n",
    "    .groupby([\"home_team\", \"home_off_line\"], as_index=False)\n",
    "    .agg(\n",
    "        toi=(\"toi\", \"sum\"),\n",
    "        xg=(\"home_xg\", \"sum\"),\n",
    "        goals=(\"home_goals\", \"sum\"),\n",
    "        games=(\"game_id\", \"nunique\")\n",
    "    )\n",
    "    .rename(columns={\n",
    "        \"home_team\": \"team\",\n",
    "        \"home_off_line\": \"off_line\"\n",
    "    })\n",
    ")\n",
    "\n",
    "away_lines = (\n",
    "    df\n",
    "    .groupby([\"away_team\", \"away_off_line\"], as_index=False)\n",
    "    .agg(\n",
    "        toi=(\"toi\", \"sum\"),\n",
    "        xg=(\"away_xg\", \"sum\"),\n",
    "        goals=(\"away_goals\", \"sum\"),\n",
    "        games=(\"game_id\", \"nunique\")\n",
    "    )\n",
    "    .rename(columns={\n",
    "        \"away_team\": \"team\",\n",
    "        \"away_off_line\": \"off_line\"\n",
    "    })\n",
    ")\n",
    "\n",
    "off_lines = pd.concat([home_lines, away_lines], ignore_index=True)\n",
    "\n",
    "off_lines = off_lines[off_lines[\"toi\"] >= 500].copy()\n",
    "\n",
    "off_lines[\"xg_60\"] = off_lines[\"xg\"] / off_lines[\"toi\"] * 3600\n",
    "off_lines[\"goals_60\"] = off_lines[\"goals\"] / off_lines[\"toi\"] * 3600  # Get team wins from team_season\n",
    "team_wins = team_season[[\"team\", \"wins\"]]\n",
    "off_lines = off_lines.merge(team_wins, on=\"team\", how=\"left\")\n",
    "\n",
    "off_lines[\"efficiency\"] = off_lines[\"xg\"] / off_lines[\"toi\"]\n",
    "\n",
    "team_toi = (\n",
    "    off_lines\n",
    "    .groupby(\"team\", as_index=False)\n",
    "    .agg(team_toi=(\"toi\", \"sum\"))\n",
    ")\n",
    "\n",
    "off_lines = off_lines.merge(team_toi, on=\"team\", how=\"left\")\n",
    "\n",
    "off_lines[\"fatigue_ratio\"] = off_lines[\"toi\"] / off_lines[\"team_toi\"]\n",
    "\n",
    "off_lines[\"overworked\"] = off_lines[\"fatigue_ratio\"] > 0.185\n",
    "\n",
    "off_lines = off_lines.sort_values(\"goals\", ascending=False)\n",
    "print(off_lines.head(32))\n",
    "print(off_lines[\"fatigue_ratio\"].describe())\n",
    "\n",
    "# Check the actual values before the boolean check\n",
    "print(off_lines[['team', 'off_line', 'toi', 'team_toi', 'fatigue_ratio']].head(10))\n",
    "\n",
    "# Try a dynamic threshold instead of a hard 0.20\n",
    "# This identifies the 'top 25%' most used lines in the league\n",
    "fatigue_threshold = off_lines[\"fatigue_ratio\"].quantile(0.75)\n",
    "print(f\"Top 25% Fatigue Threshold: {fatigue_threshold:.4f}\")\n",
    "\n",
    "off_lines[\"overworked\"] = off_lines[\"fatigue_ratio\"] > fatigue_threshold\n",
    "# 1. Use the Dynamic Threshold (Top Quartile of the actual data)\n",
    "# This finds the 'Workhorses' relative to the rest of the league\n",
    "league_fatigue_cutoff = off_lines[\"fatigue_ratio\"].quantile(0.75)\n",
    "\n",
    "# 2. Re-calculate the overworked flag\n",
    "off_lines[\"overworked\"] = off_lines[\"fatigue_ratio\"] > league_fatigue_cutoff\n",
    "\n",
    "# 3. Validation: Check if we now have 'True' values\n",
    "overworked_count = off_lines[\"overworked\"].sum()\n",
    "\n",
    "print(f\"League-Wide Fatigue Cutoff: {league_fatigue_cutoff:.4f}\")\n",
    "print(f\"Number of 'Overworked' lines identified: {overworked_count}\")\n",
    "\n",
    "# 4. Display the 'Top 10' busiest lines in the league\n",
    "print(\"\\n--- TOP 10 BUSIEST LINES (RELATIVE FATIGUE) ---\")\n",
    "display(off_lines[['team', 'off_line', 'fatigue_ratio', 'overworked']].head(10))\n",
    "# 1. Filter for only the 'Overworked' lines\n",
    "fatigue_report = off_lines[off_lines[\"overworked\"] == True].copy()\n",
    "\n",
    "# 2. Sort by the highest fatigue ratio\n",
    "fatigue_report = fatigue_report.sort_values(\"fatigue_ratio\", ascending=False)\n",
    "\n",
    "# 3. Clean up the columns for a 'scouting' look\n",
    "# We'll show the Team, the specific Line, and how much of the team's time they eat\n",
    "fatigue_report[\"Usage %\"] = (fatigue_report[\"fatigue_ratio\"] * 100).round(2).astype(str) + \"%\"\n",
    "# 1. Create a clean text label based on the overworked flag\n",
    "off_lines[\"workload_status\"] = off_lines[\"overworked\"].map({\n",
    "    True: \"FATIGUED\",\n",
    "    False: \"FRESH\",\n",
    "})\n",
    "\n",
    "# 2. Display the final scouting table\n",
    "# We'll filter for a mix of both so you can see the labels in action\n",
    "# 1. Filter the scouting table for only the second offensive lines\n",
    "second_off_report = scouting_table[scouting_table[\"off_line\"] == \"second_off\"].copy()\n",
    "\n",
    "# 2. Display the filtered table\n",
    "print(\"--- SCOUTING REPORT: SECOND LINE WORKLOAD ---\")\n",
    "display(second_off_report[['team', 'off_line', 'fatigue_ratio', 'workload_status']])\n",
    "\n",
    "# 4. Display the top 20 most overworked lines\n",
    "print(\"--- THE FATIGUE WATCHLIST: TOP 20 WORKHORSE LINES ---\")\n",
    "display(fatigue_report[['team', 'off_line', 'Usage %', 'xg_60', 'games']])\n"
   ],
   "id": "98fe1e41095938c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- PENALTY FEATURE ENGINEERING ---\n",
    "\n",
    "# 1. Calculate Taken vs Drawn PIM\n",
    "# PIM Taken = Home team penalties\n",
    "# PIM Drawn = Away team penalties (while playing at home)\n",
    "penalty_base = df.groupby('home_team').agg(\n",
    "    pim_taken=('home_penalty_minutes', 'sum'),\n",
    "    pim_drawn=('away_penalty_minutes', 'sum'),\n",
    "    total_toi=('toi', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# 2. Normalize to 'Per 60' and 'Net'\n",
    "penalty_base['pim_taken_60'] = (penalty_base['pim_taken'] / (penalty_base['total_toi'] / 3600))\n",
    "penalty_base['net_pim'] = penalty_base['pim_drawn'] - penalty_base['pim_taken']\n",
    "\n",
    "# 3. Define Thresholds (League Medians)\n",
    "median_pim_60 = penalty_base['pim_taken_60'].median()\n",
    "median_net = penalty_base['net_pim'].median()\n",
    "\n",
    "# 4. The Classification Logic (The \"Four Quadrants\")\n",
    "def classify_penalties(row):\n",
    "    is_high_risk = row['pim_taken_60'] > median_pim_60\n",
    "    is_positive_net = row['net_pim'] > median_net\n",
    "\n",
    "    if is_high_risk and not is_positive_net:\n",
    "        return \"The Liability (High Risk / Net Loss)\"\n",
    "    elif is_high_risk and is_positive_net:\n",
    "        return \"The Instigator (High Risk / Net Gain)\"\n",
    "    elif not is_high_risk and is_positive_net:\n",
    "        return \"The Professional (Disciplined / Net Gain)\"\n",
    "    else:\n",
    "        return \"The Passive (Disciplined / Net Loss)\"\n",
    "\n",
    "penalty_base['penalty_identity'] = penalty_base.apply(classify_penalties, axis=1)\n",
    "\n",
    "# 5. Merge into your Master Matrix\n",
    "team_features_df = team_features_df.join(penalty_base.set_index('home_team')[['pim_taken_60', 'net_pim', 'penalty_identity']])\n",
    "\n",
    "# --- DISPLAY THE \"SINNER\" LIST ---\n",
    "print(\"--- WHL PENALTY & RISK ANALYSIS ---\")\n",
    "display(team_features_df[['penalty_identity', 'pim_taken_60', 'net_pim']].sort_values('pim_taken_60', ascending=False))"
   ],
   "id": "a3ff434045dd6392"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
